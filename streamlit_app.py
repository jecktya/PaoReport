# -*- coding: utf-8 -*-

import streamlit as st
import requests
import urllib.parse
import html
from datetime import datetime, timedelta, timezone
import email.utils as eut
import time # time ëª¨ë“ˆ ì¶”ê°€ (API í˜¸ì¶œ ê°„ ì§€ì—°ì„ ìœ„í•´)

# API í‚¤ ë¡œë“œ
# Streamlit Secretsë¥¼ ì‚¬ìš©í•˜ì—¬ í™˜ê²½ ë³€ìˆ˜ì—ì„œ ì•ˆì „í•˜ê²Œ API í‚¤ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
NAVER_CLIENT_ID = st.secrets.get("NAVER_CLIENT_ID")
NAVER_CLIENT_SECRET = st.secrets.get("NAVER_CLIENT_SECRET")

# ì–¸ë¡ ì‚¬ ë§¤í•‘
press_name_map = {
    "chosun.com": "ì¡°ì„ ì¼ë³´", "yna.co.kr": "ì—°í•©ë‰´ìŠ¤", "hani.co.kr": "í•œê²¨ë ˆ",
    "joongang.co.kr": "ì¤‘ì•™ì¼ë³´", "mbn.co.kr": "MBN", "kbs.co.kr": "KBS",
    "sbs.co.kr": "SBS", "ytn.co.kr": "YTN", "donga.com": "ë™ì•„ì¼ë³´",
    "segye.com": "ì„¸ê³„ì¼ë³´", "munhwa.com": "ë¬¸í™”ì¼ë³´", "newsis.com": "ë‰´ì‹œìŠ¤",
    "naver.com": "ë„¤ì´ë²„", "daum.net": "ë‹¤ìŒ", "kukinews.com": "êµ­ë¯¼ì¼ë³´",
    "kookbang.dema.mil.kr": "êµ­ë°©ì¼ë³´", "edaily.co.kr": "ì´ë°ì¼ë¦¬",
    "news1.kr": "ë‰´ìŠ¤1", "mbnmoney.mbn.co.kr": "MBN", "news.kmib.co.kr": "êµ­ë¯¼ì¼ë³´",
    "jtbc.co.kr": "JTBC"
}

def extract_press_name(url):
    """
    ì£¼ì–´ì§„ URLì—ì„œ ë„ë©”ì¸ê³¼ í•´ë‹¹ ì–¸ë¡ ì‚¬ ì´ë¦„ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    ë§¤í•‘ëœ ì–¸ë¡ ì‚¬ ì´ë¦„ì´ ì—†ìœ¼ë©´ ë„ë©”ì¸ ìì²´ë¥¼ ì–¸ë¡ ì‚¬ ì´ë¦„ìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    try:
        domain = urllib.parse.urlparse(url).netloc.replace("www.", "")
        for key, name in press_name_map.items():
            if domain == key or domain.endswith("." + key):
                return domain, name
        return domain, domain
    except Exception:
        return None, None


def convert_to_mobile_link(url):
    """
    ë„¤ì´ë²„ ë‰´ìŠ¤ PC ë²„ì „ ë§í¬ë¥¼ ëª¨ë°”ì¼ ë²„ì „ ë§í¬ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    """
    if "n.news.naver.com/article" in url:
        return url.replace("n.news.naver.com/article", "n.news.naver.com/mnews/article")
    return url


def search_news(query):
    """
    ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ APIë¥¼ í˜¸ì¶œí•˜ì—¬ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    display=100ì€ í•œ ë²ˆì— ê°€ì ¸ì˜¬ ê¸°ì‚¬ ìˆ˜ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤.
    """
    enc = urllib.parse.quote(query)
    url = f"https://openapi.naver.com/v1/search/news.json?query={enc}&display=100&sort=date" # display 100ìœ¼ë¡œ ë³€ê²½
    headers = {"X-Naver-Client-Id": NAVER_CLIENT_ID, "X-Naver-Client-Secret": NAVER_CLIENT_SECRET}
    
    try:
        r = requests.get(url, headers=headers, timeout=10)
        r.raise_for_status()
        return r.json().get("items", [])
    except requests.exceptions.RequestException as e:
        st.error(f"ë‰´ìŠ¤ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return []


def parse_pubdate(pubdate_str):
    """
    API ì‘ë‹µì˜ ë°œí–‰ì¼ ë¬¸ìì—´ì„ datetime ê°ì²´ë¡œ íŒŒì‹±í•©ë‹ˆë‹¤.
    """
    try:
        dt_tuple = eut.parsedate(pubdate_str)
        if dt_tuple:
            dt = datetime(*dt_tuple[:6], tzinfo=timezone(timedelta(hours=9)))
            return dt
        return None
    except Exception:
        return None

# --- Streamlit UI ì‹œì‘ ---

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "final_articles" not in st.session_state:
    st.session_state.final_articles = [] # ì´ˆê¸° ê²€ìƒ‰ ê²°ê³¼ (í•„í„°ë§ ì „)
if "selected_keys" not in st.session_state:
    st.session_state.selected_keys = [] # ì¼ë°˜ ì„ íƒ ì²´í¬ë°•ìŠ¤ ìƒíƒœ
if "grouped_keys" not in st.session_state: # ê¸°ì‚¬ ë¬¶ìŒ í¬í•¨ ì²´í¬ë°•ìŠ¤ ìƒíƒœë¥¼ ìœ„í•œ ìƒˆë¡œìš´ ì„¸ì…˜ ìƒíƒœ
    st.session_state.grouped_keys = []
if "copied_text" not in st.session_state:
    st.session_state.copied_text = ""

# UI: ì œëª© ë° ì˜µì…˜
st.title("ğŸ“° ë‰´ìŠ¤ê²€ìƒ‰ê¸°")

# "ë™ì˜ìƒë§Œ" ì˜µì…˜ ì‚­ì œ ë° ê¸°ë³¸ê°’ì„ "ì£¼ìš”ì–¸ë¡ ì‚¬ë§Œ"ìœ¼ë¡œ ë³€ê²½
search_mode = st.radio("ğŸ—‚ï¸ ê²€ìƒ‰ ìœ í˜• ì„ íƒ", ["ì „ì²´", "ì£¼ìš”ì–¸ë¡ ì‚¬ë§Œ"], index=1) # index=1ë¡œ "ì£¼ìš”ì–¸ë¡ ì‚¬ë§Œ" ê¸°ë³¸ ì„ íƒ
st.markdown(
    f"<span style='color:gray;'>ğŸ•’ í˜„ì¬ ì‹œê°: {datetime.now(timezone(timedelta(hours=9))).strftime('%Y-%m-%d %H:%M:%S')} (4ì‹œê°„ ì´ë‚´ ë‰´ìŠ¤ë§Œ ê²€ìƒ‰í•´ìš”)</span>",
    unsafe_allow_html=True
)

def_keywords = ["ìœ¡êµ°", "êµ­ë°©", "ì™¸êµ", "ì•ˆë³´", "ë¶í•œ",
                "ì‹ ë³‘êµìœ¡ëŒ€", "í›ˆë ¨", "ê°„ë¶€", "ì¥êµ",
                "ë¶€ì‚¬ê´€", "ë³‘ì‚¬", "ìš©ì‚¬", "êµ°ë¬´ì›"]
input_keywords = st.text_input("ğŸ” í‚¤ì›Œë“œ ì…ë ¥ (ì‰¼í‘œë¡œ êµ¬ë¶„)", ", ".join(def_keywords))
keyword_list = [k.strip() for k in input_keywords.split(",") if k.strip()]

# ê²€ìƒ‰ ë²„íŠ¼
if st.button("ğŸ” ë‰´ìŠ¤ ê²€ìƒ‰"):
    with st.spinner("ë‰´ìŠ¤ ê²€ìƒ‰ ì¤‘..."):
        now = datetime.now(timezone(timedelta(hours=9)))
        url_map = {}

        for kw in keyword_list:
            items = search_news(kw)
            for a in items:
                title = html.unescape(a["title"]).replace("<b>", "").replace("</b>", "")
                desc = html.unescape(a.get("description", "")).replace("<b>", "").replace("</b>", "")
                url = a["link"]
                pub = parse_pubdate(a.get("pubDate", "")) or datetime.min.replace(tzinfo=timezone(timedelta(hours=9)))
                domain, press = extract_press_name(a.get("originallink") or url)

                # 4ì‹œê°„ í•„í„°
                if not pub or (now - pub > timedelta(hours=4)):
                    continue

                # ëª¨ë“œë³„ í•„í„° (ë™ì˜ìƒ í•„í„°ëŠ” ì œê±°ë¨)
                if search_mode == "ì£¼ìš”ì–¸ë¡ ì‚¬ë§Œ" and press not in press_name_map.values():
                    continue
                
                # ì¤‘ë³µ URL ê´€ë¦¬ ë° í‚¤ì›Œë“œ ë§¤í•‘
                if url not in url_map:
                    url_map[url] = {
                        "title": title,
                        "url": url,
                        "press": press,
                        "pubdate": pub,
                        "matched": set([kw])
                    }
                else:
                    url_map[url]["matched"].add(kw)
            
            time.sleep(0.1) # ê° í‚¤ì›Œë“œ ê²€ìƒ‰ í›„ 0.1ì´ˆ ì§€ì—° (API í˜¸ì¶œ ì œí•œ ë°©ì§€)

        # ê²°ê³¼ ì •ë¦¬ (ì´ˆê¸° ê²€ìƒ‰ ì‹œì—ëŠ” 2ê°œ ì´ìƒ í‚¤ì›Œë“œ í•„í„° ì ìš© ì•ˆ í•¨)
        articles = []
        for v in url_map.values():
            # 'ì£¼ìš”ì–¸ë¡ ì‚¬ë§Œ' ëª¨ë“œì¼ ë•ŒëŠ” 1ê°œ ì´ìƒ í‚¤ì›Œë“œ í¬í•¨ ì‹œ í†µê³¼
            if search_mode == "ì£¼ìš”ì–¸ë¡ ì‚¬ë§Œ" and not v["matched"]:
                continue
            # 'ì „ì²´' ëª¨ë“œì—ì„œëŠ” 1ê°œ ì´ìƒ í‚¤ì›Œë“œ í¬í•¨ ì‹œ í†µê³¼
            elif search_mode == "ì „ì²´" and not v["matched"]:
                continue
            
            v["matched"] = sorted(list(v["matched"]))
            articles.append(v)
        
        sorted_list = sorted(articles, key=lambda x: x['pubdate'], reverse=True)
        st.session_state.final_articles = sorted_list # í•„í„°ë§ ì „ ëª¨ë“  ê¸°ì‚¬ ì €ì¥
        st.session_state.selected_keys = [a['url'] for a in sorted_list] # ì´ˆê¸°ì—ëŠ” ëª¨ë“  ê¸°ì‚¬ ì„ íƒ ìƒíƒœë¡œ ì‹œì‘
        st.session_state.grouped_keys = [] # ê¸°ì‚¬ ë¬¶ìŒ í¬í•¨ ì²´í¬ë°•ìŠ¤ ìƒíƒœ ì´ˆê¸°í™”

# --- ê²°ê³¼ í‘œì‹œ ë° ë³µì‚¬ ì„¹ì…˜ ---
if st.session_state.final_articles:
    st.subheader("ğŸ§¾ ê¸°ì‚¬ ë¯¸ë¦¬ë³´ê¸° ë° ë³µì‚¬")
    
    col_select_all, _ = st.columns([0.3, 0.7])
    with col_select_all:
        if st.button("âœ… ì „ì²´ ì„ íƒ"):
            st.session_state.selected_keys = [a['url'] for a in st.session_state.final_articles]
            st.session_state.grouped_keys = [] # ì „ì²´ ì„ íƒ ì‹œ ê¸°ì‚¬ ë¬¶ìŒ í¬í•¨ë„ ì´ˆê¸°í™”
        if st.button("âŒ ì „ì²´ í•´ì œ"):
            st.session_state.selected_keys = []
            st.session_state.grouped_keys = []

    # ë³µì‚¬í•  ê¸°ì‚¬ë“¤ì„ ë‹´ì„ ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”
    # ë¬¶ìŒ ê¸°ì‚¬ (selected_keysì— ìˆê³  grouped_keysì— ìˆìœ¼ë©° 2ê°œ ì´ìƒ í‚¤ì›Œë“œ)
    grouped_copy_items = []
    # ì¼ë°˜ ì„ íƒ ê¸°ì‚¬ (selected_keysì— ìˆì§€ë§Œ grouped_keysì—ëŠ” ì—†ëŠ”)
    other_selected_copy_items = []

    for art in st.session_state.final_articles:
        key = art['url']
        
        # Streamlitì€ ì²´í¬ë°•ìŠ¤ ìƒíƒœë¥¼ keyë¡œ ê´€ë¦¬í•˜ë¯€ë¡œ, ì§ì ‘ session_stateë¥¼ ì—…ë°ì´íŠ¸í•˜ëŠ” í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
        def update_selection(item_key):
            if st.session_state[f"checkbox_{item_key}"]:
                if item_key not in st.session_state.selected_keys:
                    st.session_state.selected_keys.append(item_key)
            else:
                if item_key in st.session_state.selected_keys:
                    st.session_state.selected_keys.remove(item_key)

        def update_grouping(item_key):
            if st.session_state[f"group_checkbox_{item_key}"]:
                if item_key not in st.session_state.grouped_keys:
                    st.session_state.grouped_keys.append(item_key)
            else:
                if item_key in st.session_state.grouped_keys:
                    st.session_state.grouped_keys.remove(item_key)

        # ê¸°ì‚¬ ì œëª©ê³¼ ì–¸ë¡ ì‚¬ í‘œì‹œ (UI í‘œì‹œìš©)
        st.markdown(
            f"<div style='user-select: text;'>â–  {art['title']} ({art['press']})</div>",
            unsafe_allow_html=True
        )
        # ë°œí–‰ì¼ê³¼ ë§¤ì¹­ëœ í‚¤ì›Œë“œ í‘œì‹œ
        st.markdown(
            f"<div style='color:gray;font-size:13px;'>ğŸ•’ {art['pubdate'].strftime('%Y-%m-%d %H:%M')} | í‚¤ì›Œë“œ: {', '.join(art['matched'])}</div>",
            unsafe_allow_html=True
        )
        
        # ì²´í¬ë°•ìŠ¤ ì»¬ëŸ¼ ë¶„ë¦¬
        col_checkbox_select, col_checkbox_group = st.columns([0.2, 0.8])

        with col_checkbox_select:
            st.checkbox(
                "ì„ íƒ", 
                value=(key in st.session_state.selected_keys), 
                key=f"checkbox_{key}", 
                on_change=update_selection, 
                args=(key,)
            )
        
        with col_checkbox_group:
            # 'ê·¸ë£¹ ë§Œë“¤ê¸°' ì²´í¬ë°•ìŠ¤ë¥¼ í•­ìƒ í™œì„±í™” (disabled=False)
            st.checkbox(
                "ê·¸ë£¹ ë§Œë“¤ê¸°", # ì´ë¦„ ë³€ê²½: 'ê¸°ì‚¬ ë¬¶ìŒ í¬í•¨' -> 'ê·¸ë£¹ ë§Œë“¤ê¸°'
                value=(key in st.session_state.grouped_keys), 
                key=f"group_checkbox_{key}", 
                on_change=update_grouping, 
                args=(key,),
                disabled=False, # í•­ìƒ í™œì„±í™”
                help="ë¹„ìŠ·í•œ ê¸°ì‚¬ë“¤ì„ ê·¸ë£¹ìœ¼ë¡œ ì§€ì •í•©ë‹ˆë‹¤." # ë„ì›€ë§ í…ìŠ¤íŠ¸ ë³€ê²½
            )

        # ê¸°ì‚¬ ë°”ë¡œë³´ê¸° ë§í¬ ë° 1ê±´ ë³µì‚¬ ë²„íŠ¼
        col_preview, col_copy = st.columns([0.75, 0.25])
        with col_preview:
            st.markdown(f"[ğŸ“ ê¸°ì‚¬ ë°”ë¡œë³´ê¸°]({convert_to_mobile_link(art['url'])})")
        with col_copy:
            if st.button("ğŸ“‹ 1ê±´ ë³µì‚¬", key=f"copy_{key}"):
                # 1ê±´ ë³µì‚¬ëŠ” ê·¸ëƒ¥ ì„ íƒëœ ê¸°ì‚¬ í˜•ì‹ìœ¼ë¡œ (â–  ì œëª© (ì–¸ë¡ ì‚¬))
                ctext = f"â–  {art['title']} ({art['press']})\n{convert_to_mobile_link(art['url'])}"
                st.session_state.copied_text = ctext
                st.experimental_rerun()

        # ë³µì‚¬ëœ ë‚´ìš© í‘œì‹œ (ê°€ì¥ ìµœê·¼ ë³µì‚¬ëœ 1ê±´ë§Œ)
        if st.session_state.get("copied_text", "").startswith(f"â–  {art['title']}"): # ì‹œì‘ ë¬¸ì 'â– 'ë¡œ ë³€ê²½
            st.text_area("ë³µì‚¬ëœ ë‚´ìš©", st.session_state.copied_text, height=80, key=f"copied_area_{key}")

        # ë³µì‚¬í•  í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€ (ê¸°ì‚¬ ë¬¶ìŒ vs ì¼ë°˜ ì„ íƒ ë¶„ë¦¬)
        if key in st.session_state.selected_keys: # 'ì„ íƒ'ëœ ê¸°ì‚¬ë§Œ ê³ ë ¤
            # ë¬¶ìŒ ê¸°ì‚¬ í˜•ì‹: - ì œëª© (ì–¸ë¡ ì‚¬)
            item_text_grouped = f"- {art['title']} ({art['press']})\n{convert_to_mobile_link(art['url'])}"
            # ê·¸ëƒ¥ ì„ íƒëœ ê¸°ì‚¬ í˜•ì‹: â–  ì œëª© (ì–¸ë¡ ì‚¬)
            item_text_normal = f"â–  {art['title']} ({art['press']})\n{convert_to_mobile_link(art['url'])}"
            
            # 'ê·¸ë£¹ ë§Œë“¤ê¸°'ê°€ ì²´í¬ë˜ì—ˆìœ¼ë©´ ë¬¶ìŒ ëª©ë¡ì— ì¶”ê°€ (í‚¤ì›Œë“œ ê°œìˆ˜ ì¡°ê±´ ì œê±°)
            if key in st.session_state.grouped_keys:
                grouped_copy_items.append(item_text_grouped)
            else: # 'ì„ íƒ'ë˜ì—ˆì§€ë§Œ ê·¸ë£¹ ì¡°ê±´ì€ ë§Œì¡±í•˜ì§€ ì•ŠëŠ” ê²½ìš° ì¼ë°˜ ëª©ë¡ì— ì¶”ê°€
                other_selected_copy_items.append(item_text_normal)

    # ìµœì¢… result_texts êµ¬ì„± (ìˆœì„œ: ë¬¶ìŒ ê¸°ì‚¬ -> ì¼ë°˜ ì„ íƒ ê¸°ì‚¬)
    result_texts = []
    if grouped_copy_items:
        result_texts.append("â–  ì„ íƒëœê´€ë ¨ë‚´ìš© ê´€ë ¨") # ê³µí†µ ì œëª©
        result_texts.extend(grouped_copy_items)
    
    # ë¬¶ìŒ ê¸°ì‚¬ ë’¤ì— ì¼ë°˜ ì„ íƒ ê¸°ì‚¬ ì¶”ê°€
    if other_selected_copy_items:
        # ë¬¶ìŒ ê¸°ì‚¬ê°€ ì—†ì—ˆê³  ì¼ë°˜ ì„ íƒ ê¸°ì‚¬ë§Œ ìˆë‹¤ë©´, ì œëª©ì„ ë¶™ì´ì§€ ì•ŠìŠµë‹ˆë‹¤.
        # ì‚¬ìš©ì ìš”ì²­ì— ë”°ë¼ "ì„ íƒëœê´€ë ¨ë‚´ìš© ê´€ë ¨" ì œëª©ì€ ë¬¶ìŒ ê¸°ì‚¬ì—ë§Œ ë¶™ìŠµë‹ˆë‹¤.
        result_texts.extend(other_selected_copy_items)

    final_txt = "\n\n".join(result_texts)
    st.text_area("ğŸ“ ë³µì‚¬í•  ë‰´ìŠ¤ ëª©ë¡", final_txt, height=300)
    
    # ë³µì‚¬ ë‚´ìš© ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
    st.download_button("ğŸ“„ ë³µì‚¬ ë‚´ìš© ë‹¤ìš´ë¡œë“œ (.txt)", final_txt, file_name="news.txt")
    st.markdown("ğŸ“‹ ìœ„ í…ìŠ¤íŠ¸ë¥¼ ì§ì ‘ ë³µì‚¬í•˜ê±°ë‚˜ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ì„ ëˆŒëŸ¬ ì €ì¥í•˜ì„¸ìš”.")
