# -*- coding: utf-8 -*-

import streamlit as st
import requests
import urllib.parse
import html
from datetime import datetime, timedelta
import email.utils as eut

NAVER_CLIENT_ID = st.secrets["NAVER_CLIENT_ID"]
NAVER_CLIENT_SECRET = st.secrets["NAVER_CLIENT_SECRET"]

press_name_map = {
    "chosun.com": "ì¡°ì„ ì¼ë³´", "yna.co.kr": "ì—°í•©ë‰´ìŠ¤", "hani.co.kr": "í•œê²¨ë ˆ",
    "joongang.co.kr": "ì¤‘ì•™ì¼ë³´", "mbn.co.kr": "MBN", "kbs.co.kr": "KBS",
    "sbs.co.kr": "SBS", "ytn.co.kr": "YTN", "donga.com": "ë™ì•„ì¼ë³´",
    "segye.com": "ì„¸ê³„ì¼ë³´", "munhwa.com": "ë¬¸í™”ì¼ë³´", "newsis.com": "ë‰´ì‹œìŠ¤",
    "naver.com": "ë„¤ì´ë²„", "daum.net": "ë‹¤ìŒ", "kukinews.com": "êµ­ë¯¼ì¼ë³´",
    "kookbang.dema.mil.kr": "êµ­ë°©ì¼ë³´", "edaily.co.kr": "ì´ë°ì¼ë¦¬",
    "news1.kr": "ë‰´ìŠ¤1", "mbnmoney.mbn.co.kr": "MBN", "news.kmib.co.kr": "êµ­ë¯¼ì¼ë³´",
    "jtbc.co.kr": "JTBC"
}

def extract_press_name(url):
    try:
        domain = urllib.parse.urlparse(url).netloc.replace("www.", "")
        return domain, press_name_map.get(domain, domain)
    except Exception as e:
        return None, None

def convert_to_mobile_link(url):
    if "n.news.naver.com/article" in url:
        return url.replace("n.news.naver.com/article", "n.news.naver.com/mnews/article")
    return url

def search_news(query):
    enc_query = urllib.parse.quote(query)
    url = f"https://openapi.naver.com/v1/search/news.json?query={enc_query}&display=30&sort=date"
    headers = {
        "X-Naver-Client-Id": NAVER_CLIENT_ID,
        "X-Naver-Client-Secret": NAVER_CLIENT_SECRET,
    }
    res = requests.get(url, headers=headers)
    if res.status_code == 200:
        return res.json().get("items", [])
    return []

def parse_pubdate(pubdate_str):
    try:
        return datetime(*eut.parsedate(pubdate_str)[:6])
    except Exception:
        return None

if "final_articles" not in st.session_state:
    st.session_state.final_articles = []
if "selected_keys" not in st.session_state:
    st.session_state.selected_keys = []
if "copied_text" not in st.session_state:
    st.session_state.copied_text = ""

st.title("ğŸ“° ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ê¸°")
search_mode = st.radio("ğŸ—‚ï¸ ê²€ìƒ‰ ìœ í˜• ì„ íƒ", ["ì „ì²´", "ë™ì˜ìƒë§Œ (ìµœê·¼ 4ì‹œê°„)", "ì£¼ìš”ì–¸ë¡ ì‚¬ë§Œ"])

def_keywords = ["ìœ¡êµ°", "êµ­ë°©", "ì™¸êµ", "ì•ˆë³´", "ë¶í•œ",
                "ì‹ ë³‘êµìœ¡ëŒ€", "í›ˆë ¨", "ê°„ë¶€", "ì¥êµ",
                "ë¶€ì‚¬ê´€", "ë³‘ì‚¬", "ìš©ì‚¬", "êµ°ë¬´ì›"]
input_keywords = st.text_input("ğŸ” í‚¤ì›Œë“œ ì…ë ¥ (ì‰¼í‘œë¡œ êµ¬ë¶„)", ", ".join(def_keywords))
keyword_list = [k.strip() for k in input_keywords.split(",") if k.strip()]

if st.button("ğŸ” ë‰´ìŠ¤ ê²€ìƒ‰"):
    with st.spinner("ë‰´ìŠ¤ ê²€ìƒ‰ ì¤‘..."):
        now = datetime.utcnow()
        all_articles = []
        for keyword in keyword_list:
            items = search_news(keyword)
            for a in items:
                title = html.unescape(a["title"]).replace("<b>", "").replace("</b>", "")
                desc = html.unescape(a.get("description", "")).replace("<b>", "").replace("</b>", "")
                url = a["link"]
                pubdate = parse_pubdate(a.get("pubDate", ""))
                domain, press = extract_press_name(a.get("originallink") or url)

                if search_mode == "ì£¼ìš”ì–¸ë¡ ì‚¬ë§Œ" and press not in press_name_map.values():
                    continue
                if search_mode == "ë™ì˜ìƒë§Œ (ìµœê·¼ 4ì‹œê°„)":
                    if not pubdate or (now - pubdate > timedelta(hours=4)):
                        continue
                    if press not in press_name_map.values():
                        continue
                    if not ("ë™ì˜ìƒ" in desc or "ì˜ìƒ" in desc or any(kw in title for kw in ["ì˜ìƒ", "ë™ì˜ìƒ", "ì˜ìƒë³´ê¸°"])):
                        continue

                article = {
                    "title": title,
                    "url": url,
                    "press": press,
                    "pubdate": pubdate,
                    "key": url
                }
                all_articles.append(article)

        unique_articles = {a["url"]: a for a in all_articles}
        sorted_articles = sorted(unique_articles.values(), key=lambda x: x["pubdate"] or datetime.min, reverse=True)
        st.session_state.final_articles = sorted_articles
        st.session_state.selected_keys = [a["key"] for a in sorted_articles]

if st.session_state.final_articles:
    st.subheader("ğŸ§¾ ê¸°ì‚¬ ë¯¸ë¦¬ë³´ê¸° ë° ë³µì‚¬")

    col1, col2 = st.columns([0.3, 0.7])
    with col1:
        if st.button("âœ… ì „ì²´ ì„ íƒ"):
            st.session_state.selected_keys = [a["key"] for a in st.session_state.final_articles]
        if st.button("âŒ ì „ì²´ í•´ì œ"):
            st.session_state.selected_keys = []

    result_lines = []
    for article in st.session_state.final_articles:
        key = article["key"]
        checked = key in st.session_state.selected_keys
        pub_str = article["pubdate"].strftime("%Y-%m-%d %H:%M") if article["pubdate"] else "ì‹œê°„ ì—†ìŒ"
            st.markdown(f"<div style='user-select: text;'>â–  {article['title']} ({article['press']})</div>", unsafe_allow_html=True)
    st.markdown(f"<div style='color:gray;font-size:13px;'>ğŸ•’ {pub_str}</div>", unsafe_allow_html=True)
    new_check = st.checkbox("ì„ íƒ", value=checked, key=key)

        if new_check and key not in st.session_state.selected_keys:
            st.session_state.selected_keys.append(key)
        elif not new_check and key in st.session_state.selected_keys:
            st.session_state.selected_keys.remove(key)

        col_preview, col_copy = st.columns([0.75, 0.25])
        with col_preview:
            st.markdown(f"[ğŸ“ ê¸°ì‚¬ ë°”ë¡œë³´ê¸°]({convert_to_mobile_link(article['url'])})")
        with col_copy:
            if st.button(f"ğŸ“‹ 1ê±´ ë³µì‚¬", key=key + "_copy"):
                st.session_state["copied_text"] = f"[{article['press']}] {article['title']}\n{convert_to_mobile_link(article['url'])}"

        if st.session_state.get("copied_text") and st.session_state["copied_text"].startswith(f"[{article['press']}] {article['title']}"):
            st.text_area("ë³µì‚¬ëœ ë‚´ìš©", st.session_state["copied_text"], height=80)

        if key in st.session_state.selected_keys:
            result_lines.append(f"â–  {article['title']} ({article['press']})\n{convert_to_mobile_link(article['url'])}")

    final_text = "\n\n".join(result_lines)
    st.text_area("ğŸ“ ë³µì‚¬í•  ë‰´ìŠ¤ ëª©ë¡", final_text, height=300)
    st.download_button("ğŸ“„ ë³µì‚¬ ë‚´ìš© ë‹¤ìš´ë¡œë“œ (.txt)", final_text, file_name="news.txt")
    st.markdown("ğŸ“‹ ìœ„ í…ìŠ¤íŠ¸ë¥¼ ì§ì ‘ ë³µì‚¬í•˜ê±°ë‚˜ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ì„ ëˆŒëŸ¬ ì €ì¥í•˜ì„¸ìš”.")
