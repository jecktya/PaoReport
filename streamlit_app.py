# -*- coding: utf-8 -*-

import streamlit as st
import requests
import urllib.parse
import html
from datetime import datetime, timedelta, timezone
import email.utils as eut
import time
import re # ì •ê·œí‘œí˜„ì‹ ëª¨ë“ˆ ì¶”ê°€

# scikit-learn ì„í¬íŠ¸ (ìë™ ê·¸ë£¹í™”ì— í•„ìš”)
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import AgglomerativeClustering
from sklearn.metrics.pairwise import cosine_similarity # ì´ ì„í¬íŠ¸ëŠ” ë” ì´ìƒ ì§ì ‘ ì‚¬ìš©ë˜ì§€ ì•Šì§€ë§Œ, ë‹¤ë¥¸ ê³³ì—ì„œ ì‚¬ìš©ë  ê°€ëŠ¥ì„±ì„ ìœ„í•´ ìœ ì§€

# API í‚¤ ë¡œë“œ
# Streamlit Secretsë¥¼ ì‚¬ìš©í•˜ì—¬ í™˜ê²½ ë³€ìˆ˜ì—ì„œ ì•ˆì „í•˜ê²Œ API í‚¤ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
NAVER_CLIENT_ID = st.secrets.get("NAVER_CLIENT_ID")
NAVER_CLIENT_SECRET = st.secrets.get("NAVER_CLIENT_SECRET")

# ì–¸ë¡ ì‚¬ ë§¤í•‘
press_name_map = {
    "chosun.com": "ì¡°ì„ ì¼ë³´", "yna.co.kr": "ì—°í•©ë‰´ìŠ¤", "hani.co.kr": "í•œê²¨ë ˆ",
    "joongang.co.kr": "ì¤‘ì•™ì¼ë³´", "mbn.co.kr": "MBN", "kbs.co.kr": "KBS",
    "sbs.co.kr": "SBS", "ytn.co.kr": "YTN", "donga.com": "ë™ì•„ì¼ë³´",
    "segye.com": "ì„¸ê³„ì¼ë³´", "munhwa.com": "ë¬¸í™”ì¼ë³´", "newsis.com": "ë‰´ì‹œìŠ¤",
    "naver.com": "ë„¤ì´ë²„", "daum.net": "ë‹¤ìŒ", "kukinews.com": "êµ­ë¯¼ì¼ë³´",
    "kookbang.dema.mil.kr": "êµ­ë°©ì¼ë³´", "edaily.co.kr": "ì´ë°ì¼ë¦¬",
    "news1.kr": "ë‰´ìŠ¤1", "mbnmoney.mbn.co.kr": "MBN", "news.kmib.co.kr": "êµ­ë¯¼ì¼ë³´",
    "jtbc.co.kr": "JTBC"
}

def extract_press_name(url):
    """
    ì£¼ì–´ì§„ URLì—ì„œ ë„ë©”ì¸ê³¼ í•´ë‹¹ ì–¸ë¡ ì‚¬ ì´ë¦„ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    ë§¤í•‘ëœ ì–¸ë¡ ì‚¬ ì´ë¦„ì´ ì—†ìœ¼ë©´ ë„ë©”ì¸ ìì²´ë¥¼ ì–¸ë¡ ì‚¬ ì´ë¦„ìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    try:
        domain = urllib.parse.urlparse(url).netloc.replace("www.", "")
        for key, name in press_name_map.items():
            if domain == key or domain.endswith("." + key):
                return domain, name
        return domain, domain
    except Exception:
        return None, None


def convert_to_mobile_link(url):
    """
    ë„¤ì´ë²„ ë‰´ìŠ¤ PC ë²„ì „ ë§í¬ë¥¼ ëª¨ë°”ì¼ ë²„ì „ ë§í¬ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    """
    if "n.news.naver.com/article" in url:
        return url.replace("n.news.naver.com/article", "n.news.naver.com/mnews/article")
    return url


def search_news(query):
    """
    ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ APIë¥¼ í˜¸ì¶œí•˜ì—¬ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    display=100ì€ í•œ ë²ˆì— ê°€ì ¸ì˜¬ ê¸°ì‚¬ ìˆ˜ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤.
    """
    enc = urllib.parse.quote(query)
    url = f"https://openapi.naver.com/v1/search/news.json?query={enc}&display=100&sort=date" # display 100ìœ¼ë¡œ ë³€ê²½
    headers = {"X-Naver-Client-Id": NAVER_CLIENT_ID, "X-Naver-Client-Secret": NAVER_CLIENT_SECRET}
    
    try:
        r = requests.get(url, headers=headers, timeout=10)
        r.raise_for_status()
        return r.json().get("items", [])
    except requests.exceptions.RequestException as e:
        st.error(f"ë‰´ìŠ¤ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return []


def parse_pubdate(pubdate_str):
    """
    API ì‘ë‹µì˜ ë°œí–‰ì¼ ë¬¸ìì—´ì„ datetime ê°ì²´ë¡œ íŒŒì‹±í•©ë‹ˆë‹¤.
    """
    try:
        dt_tuple = eut.parsedate(pubdate_str)
        if dt_tuple:
            dt = datetime(*dt_tuple[:6], tzinfo=timezone(timedelta(hours=9)))
            return dt
        return None
    except Exception:
        return None

# --- ìë™ ê·¸ë£¹í™” ê¸°ëŠ¥ ì¶”ê°€ ---
def preprocess_text(text):
    """í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬: HTML íƒœê·¸ ì œê±°, íŠ¹ìˆ˜ë¬¸ì ì œê±°, ì†Œë¬¸ì ë³€í™˜"""
    text = html.unescape(text)
    text = re.sub(r'<[^>]+>', '', text) # HTML íƒœê·¸ ì œê±°
    text = re.sub(r'[^\w\s]', '', text) # íŠ¹ìˆ˜ë¬¸ì ì œê±° (ì•ŒíŒŒë²³, ìˆ«ì, ì–¸ë”ìŠ¤ì½”ì–´, ê³µë°± ì œì™¸)
    return text.lower()

def get_common_keywords_in_group(articles_in_group):
    """ê·¸ë£¹ ë‚´ ê¸°ì‚¬ë“¤ì˜ ê³µí†µ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œ"""
    if not articles_in_group:
        return []

    # ëª¨ë“  ê¸°ì‚¬ë“¤ì˜ ë§¤ì¹­ëœ í‚¤ì›Œë“œ ì§‘í•©ì„ ê°€ì ¸ì™€ì„œ êµì§‘í•©ì„ ì°¾ìŒ
    # ê° ê¸°ì‚¬ì˜ 'matched' í•„ë“œëŠ” ì´ë¯¸ setìœ¼ë¡œ ë³€í™˜ë˜ì–´ ìˆë‹¤ê³  ê°€ì •
    if not articles_in_group[0].get('matched'): # ì²« ê¸°ì‚¬ì— ë§¤ì¹­ í‚¤ì›Œë“œê°€ ì—†ìœ¼ë©´ ë¹ˆ ì„¸íŠ¸ë¡œ ì‹œì‘
        common_keywords_set = set()
    else:
        common_keywords_set = set(articles_in_group[0]['matched'])
    
    for i in range(1, len(articles_in_group)):
        if articles_in_group[i].get('matched'):
            common_keywords_set.intersection_update(set(articles_in_group[i]['matched']))
        else: # ì¤‘ê°„ì— ë§¤ì¹­ í‚¤ì›Œë“œ ì—†ëŠ” ê¸°ì‚¬ê°€ ìˆìœ¼ë©´ ê³µí†µ í‚¤ì›Œë“œ ì—†ìŒ
            common_keywords_set = set()
            break
            
    return sorted(list(common_keywords_set))

def auto_group_articles(articles, max_group_size=3, similarity_threshold=0.7): # <--- similarity_thresholdë¥¼ 0.7ë¡œ ë³€ê²½
    """
    ê¸°ì‚¬ë“¤ì„ ìë™ìœ¼ë¡œ ê·¸ë£¹í™”í•˜ê³ , ê° ê·¸ë£¹ì˜ ê¸°ì‚¬ ìˆ˜ë¥¼ ì œí•œí•©ë‹ˆë‹¤.
    """
    if len(articles) < 2: # ê·¸ë£¹í™”í•  ê¸°ì‚¬ê°€ 2ê°œ ë¯¸ë§Œì´ë©´ ê·¸ë£¹ ìƒì„± ì•ˆ í•¨
        return []

    # í…ìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„ (ì œëª© + ë‚´ìš©)
    texts = []
    for art in articles:
        # 'desc' í•„ë“œê°€ ì—†ì„ ê²½ìš°ë¥¼ ëŒ€ë¹„í•˜ì—¬ ê¸°ë³¸ê°’ ì„¤ì •
        combined_text = preprocess_text(art['title'] + " " + art.get('desc', ''))
        texts.append(combined_text)

    if not texts or all(not t.strip() for t in texts): # ëª¨ë“  í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆê±°ë‚˜ ê³µë°±ë§Œ ìˆëŠ” ê²½ìš°
        return []

    # TF-IDF ë²¡í„°í™”
    # max_featuresë¥¼ ì‚¬ìš©í•˜ì—¬ ë„ˆë¬´ ë§ì€ íŠ¹ì„±ìœ¼ë¡œ ì¸í•œ ë©”ëª¨ë¦¬ ë¬¸ì œë¥¼ ë°©ì§€
    vectorizer = TfidfVectorizer(max_features=1000, stop_words=None) # í•œêµ­ì–´ ë¶ˆìš©ì–´ëŠ” ì§ì ‘ ì²˜ë¦¬í•˜ê±°ë‚˜, gensim ë“± ì‚¬ìš©
    try:
        tfidf_matrix = vectorizer.fit_transform(texts)
    except ValueError: # ëª¨ë“  ë¬¸ì„œê°€ ë¹„ì–´ìˆê±°ë‚˜ ë‹¨ì–´ê°€ ì—†ëŠ” ê²½ìš°
        return []

    # AgglomerativeClustering (ì‘ì§‘í˜• ê³„ì¸µì  í´ëŸ¬ìŠ¤í„°ë§)
    # distance_threshold: í´ëŸ¬ìŠ¤í„° ë³‘í•©ì„ ì¤‘ë‹¨í•  ê±°ë¦¬ ì„ê³„ê°’ (1 - ìœ ì‚¬ë„)
    # metric='cosine': ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ê±°ë¦¬ ì²™ë„ë¡œ ì‚¬ìš© (ëª¨ë¸ì´ ë‚´ë¶€ì ìœ¼ë¡œ ê³„ì‚°)
    # linkage='average': í‰ê·  ì—°ê²°ë²• (í´ëŸ¬ìŠ¤í„° ê°„ í‰ê·  ê±°ë¦¬ë¥¼ ì‚¬ìš©)
    
    # ìœ ì‚¬ë„ ì„ê³„ê°’ì„ ê±°ë¦¬ ì„ê³„ê°’ìœ¼ë¡œ ë³€í™˜ (1 - ìœ ì‚¬ë„)
    model = AgglomerativeClustering(n_clusters=None, metric='cosine', linkage='average', distance_threshold=1 - similarity_threshold)
    
    # Sparse data error í•´ê²°: .toarray()ë¥¼ ì‚¬ìš©í•˜ì—¬ dense arrayë¡œ ë³€í™˜
    # ëª…ì‹œì ì¸ ë³€ìˆ˜ í• ë‹¹ìœ¼ë¡œ ë”ìš± í™•ì‹¤í•˜ê²Œ dense array ì „ë‹¬
    dense_tfidf_matrix = tfidf_matrix.toarray()
    labels = model.fit_predict(dense_tfidf_matrix) # <--- dense_tfidf_matrix ì „ë‹¬

    # í´ëŸ¬ìŠ¤í„° ê²°ê³¼ ì •ë¦¬
    clusters = {}
    for i, label in enumerate(labels):
        if label not in clusters:
            clusters[label] = []
        clusters[label].append(articles[i])

    grouped_results = []
    for group_id, cluster_articles in clusters.items():
        # ê·¸ë£¹ ë‚´ ê¸°ì‚¬ ìˆ˜ê°€ 1ê°œì¸ ê²½ìš°ëŠ” ì œì™¸ (ê·¸ë£¹ìœ¼ë¡œ ê°„ì£¼í•˜ì§€ ì•ŠìŒ)
        if len(cluster_articles) < 2:
            continue
        
        # ê¸°ì‚¬ ìˆ˜ê°€ max_group_sizeë¥¼ ì´ˆê³¼í•˜ë©´, í‚¤ì›Œë“œ ì¶œí˜„ íšŸìˆ˜ê°€ ë§ì€ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ìƒìœ„ Nê°œë§Œ ì„ íƒ
        # kw_count í•„ë“œê°€ ì—†ëŠ” ê²½ìš°ë¥¼ ëŒ€ë¹„í•˜ì—¬ 0ìœ¼ë¡œ ê¸°ë³¸ê°’ ì„¤ì •
        if len(cluster_articles) > max_group_size:
            # ë§¤ì¹­ëœ í‚¤ì›Œë“œ ê°œìˆ˜ê°€ ë§ì€ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ì„ íƒ
            cluster_articles.sort(key=lambda x: len(x.get('matched', [])), reverse=True)
            cluster_articles = cluster_articles[:max_group_size]
        
        # ê·¸ë£¹ ë‚´ ê³µí†µ í‚¤ì›Œë“œ ì¶”ì¶œ
        common_kws = get_common_keywords_in_group(cluster_articles)
        
        grouped_results.append({
            'group_id': group_id,
            'articles': cluster_articles,
            'common_keywords': common_kws
        })
    
    # ê·¸ë£¹ ë‚´ ê¸°ì‚¬ ìˆ˜(descending), ê·¸ë£¹ ID(ascending)ë¡œ ì •ë ¬
    grouped_results.sort(key=lambda x: (-len(x['articles']), x['group_id']))
    
    return grouped_results

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "final_articles" not in st.session_state:
    st.session_state.final_articles = [] # ì´ˆê¸° ê²€ìƒ‰ ê²°ê³¼ (í•„í„°ë§ ì „)
if "selected_keys" not in st.session_state:
    st.session_state.selected_keys = [] # ì¼ë°˜ ì„ íƒ ì²´í¬ë°•ìŠ¤ ìƒíƒœ
if "manual_grouped_keys" not in st.session_state: # ìˆ˜ë™ ê·¸ë£¹í™” ì²´í¬ë°•ìŠ¤ ìƒíƒœë¥¼ ìœ„í•œ ìƒˆë¡œìš´ ì„¸ì…˜ ìƒíƒœ
    st.session_state.manual_grouped_keys = []
if "copied_text" not in st.session_state:
    st.session_state.copied_text = ""
# ìë™ ê·¸ë£¹í™” ê´€ë ¨ ì„¸ì…˜ ìƒíƒœ
if "auto_groups" not in st.session_state:
    st.session_state.auto_groups = [] # ìë™ ìƒì„±ëœ ê·¸ë£¹ ëª©ë¡
if "selected_display_mode" not in st.session_state: # 'selected_group_id' -> 'selected_display_mode'ë¡œ ë³€ê²½
    st.session_state.selected_display_mode = "all_individual" # ê¸°ë³¸ê°’: ëª¨ë“  ê°œë³„ ê¸°ì‚¬ í‘œì‹œ

# current_display_articlesë¥¼ ì „ì—­ì ìœ¼ë¡œ ì´ˆê¸°í™”í•˜ì—¬ NameError ë°©ì§€
current_display_articles = [] # ì´ ë³€ìˆ˜ëŠ” "ì „ì²´ ì„ íƒ/í•´ì œ" ë²„íŠ¼ì˜ ë²”ìœ„ë¥¼ ê²°ì •í•©ë‹ˆë‹¤.

# UI: ì œëª© ë° ì˜µì…˜
st.title("ğŸ“° ë‰´ìŠ¤ê²€ìƒ‰ê¸°")
search_mode = st.radio("ğŸ—‚ï¸ ê²€ìƒ‰ ìœ í˜• ì„ íƒ", ["ì „ì²´", "ì£¼ìš”ì–¸ë¡ ì‚¬ë§Œ"], index=1)
st.markdown(
    f"<span style='color:gray;'>ğŸ•’ í˜„ì¬ ì‹œê°: {datetime.now(timezone(timedelta(hours=9))).strftime('%Y-%m-%d %H:%M:%S')} (4ì‹œê°„ ì´ë‚´ ë‰´ìŠ¤ë§Œ ê²€ìƒ‰í•´ìš”)</span>",
    unsafe_allow_html=True
)

def_keywords = ["ìœ¡êµ°", "êµ­ë°©", "ì™¸êµ", "ì•ˆë³´", "ë¶í•œ",
                "ì‹ ë³‘êµìœ¡ëŒ€", "í›ˆë ¨", "ê°„ë¶€", "ì¥êµ",
                "ë¶€ì‚¬ê´€", "ë³‘ì‚¬", "ìš©ì‚¬", "êµ°ë¬´ì›"]
input_keywords = st.text_input("ğŸ” í‚¤ì›Œë“œ ì…ë ¥ (ì‰¼í‘œë¡œ êµ¬ë¶„)", ", ".join(def_keywords))
keyword_list = [k.strip() for k in input_keywords.split(",") if k.strip()]

# ê²€ìƒ‰ ë²„íŠ¼
if st.button("ğŸ” ë‰´ìŠ¤ ê²€ìƒ‰"):
    with st.spinner("ë‰´ìŠ¤ ê²€ìƒ‰ ì¤‘..."):
        now = datetime.now(timezone(timedelta(hours=9)))
        url_map = {}

        for kw in keyword_list:
            items = search_news(kw)
            for a in items:
                title = html.unescape(a["title"]).replace("<b>", "").replace("</b>", "")
                desc = html.unescape(a.get("description", "")).replace("<b>", "").replace("</b>", "")
                url = a["link"]
                pub = parse_pubdate(a.get("pubDate", "")) or datetime.min.replace(tzinfo=timezone(timedelta(hours=9)))
                domain, press = extract_press_name(a.get("originallink") or url)

                if not pub or (now - pub > timedelta(hours=4)):
                    continue

                if search_mode == "ì£¼ìš”ì–¸ë¡ ì‚¬ë§Œ" and press not in press_name_map.values():
                    continue
                
                # í‚¤ì›Œë“œ ë§¤ì¹­ ë° ì¹´ìš´íŠ¸ (auto_group_articles í•¨ìˆ˜ì—ì„œ ì‚¬ìš©ë  kw_countì™€ matchedë¥¼ ìœ„í•´)
                kwcnt = {}
                for k in keyword_list: # ì‚¬ìš©ìê°€ ì…ë ¥í•œ ëª¨ë“  í‚¤ì›Œë“œë¥¼ ëŒ€ìƒìœ¼ë¡œ ë§¤ì¹­
                    pat = re.compile(re.escape(k), re.IGNORECASE)
                    c = pat.findall(title + " " + desc)
                    if c: kwcnt[k] = len(c)

                if url not in url_map:
                    url_map[url] = {
                        "title": title,
                        "url": url,
                        "press": press,
                        "pubdate": pub, # datetime ê°ì²´ ìœ ì§€
                        "matched": set(kwcnt.keys()), # ë§¤ì¹­ëœ í‚¤ì›Œë“œë§Œ ì €ì¥
                        "desc": desc, # ìë™ ê·¸ë£¹í™”ë¥¼ ìœ„í•´ description ì¶”ê°€
                        "kw_count": sum(kwcnt.values()) # í‚¤ì›Œë“œ ì´ ì¶œí˜„ íšŸìˆ˜
                    }
                else:
                    url_map[url]["matched"].update(kwcnt.keys())
                    url_map[url]["kw_count"] += sum(kwcnt.values())
            
            time.sleep(0.1)

        articles = []
        for v in url_map.values():
            if search_mode == "ì£¼ìš”ì–¸ë¡ ì‚¬ë§Œ" and not v["matched"]:
                continue
            elif search_mode == "ì „ì²´" and not v["matched"]:
                continue
            
            v["matched"] = sorted(list(v["matched"])) # setì„ listë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥
            articles.append(v)
        
        sorted_list = sorted(articles, key=lambda x: x['pubdate'], reverse=True)
        st.session_state.final_articles = sorted_list
        st.session_state.selected_keys = [a['url'] for a in sorted_list] # ì´ˆê¸°ì—ëŠ” ëª¨ë“  ê¸°ì‚¬ ì„ íƒ
        st.session_state.manual_grouped_keys = [] # ìˆ˜ë™ ê·¸ë£¹í™” ìƒíƒœ ì´ˆê¸°í™”
        
        # ìë™ ê·¸ë£¹í™” ì‹¤í–‰ ë° ê²°ê³¼ ì €ì¥
        st.session_state.auto_groups = auto_group_articles(sorted_list)
        st.session_state.selected_display_mode = "all_individual" # ê·¸ë£¹ ì„ íƒ ì´ˆê¸°í™”

# --- ê²°ê³¼ í‘œì‹œ ë° ë³µì‚¬ ì„¹ì…˜ ---
if st.session_state.final_articles:
    st.subheader("ğŸ§¾ ê¸°ì‚¬ ë¯¸ë¦¬ë³´ê¸° ë° ë³µì‚¬")
    
    # ê²°ê³¼ ì¶œë ¥ ë°©ì‹ selectbox ì˜µì…˜ êµ¬ì„±
    display_mode_options = {
        "all_individual": "ëª¨ë“  ê¸°ì‚¬ (ê°œë³„ ë³´ê¸°)",
        "no_manual_group": "ê·¸ë£¹ ì—†ëŠ” ê¸°ì‚¬ ë³´ê¸°", 
        "all_auto_groups": "ê·¸ë£¹í™”ëœ ê¸°ì‚¬ë§Œ ë³´ê¸°" # ëª…ì¹­ ë³€ê²½
    }
    
    # selectboxì˜ options ë¦¬ìŠ¤íŠ¸ì™€ default index ì„¤ì •
    options_keys = list(display_mode_options.keys())
    options_values = list(display_mode_options.values())
    
    # ê¸°ë³¸ê°’ì„ "ëª¨ë“  ê¸°ì‚¬ (ê°œë³„ ë³´ê¸°)" (all_individual)ë¡œ ì„¤ì •
    default_index = options_keys.index("all_individual") 

    st.session_state.selected_display_mode = st.selectbox(
        "âœ¨ ê²°ê³¼ ì¶œë ¥ ë°©ì‹", # ìš©ì–´ ë³€ê²½
        options=options_keys,
        format_func=lambda x: display_mode_options[x],
        index=default_index, # ê¸°ë³¸ê°’ ì„¤ì •
        key="display_mode_selectbox"
    )

    # current_display_articles ì—…ë°ì´íŠ¸ (ì „ì²´ ì„ íƒ/í•´ì œ ë²„íŠ¼ì˜ ë²”ìœ„)
    if st.session_state.selected_display_mode == "all_individual":
        current_display_articles = st.session_state.final_articles
    elif st.session_state.selected_display_mode == "no_manual_group":
        current_display_articles = [
            art for art in st.session_state.final_articles 
            if art['url'] not in st.session_state.manual_grouped_keys
        ]
    elif st.session_state.selected_display_mode == "all_auto_groups":
        all_auto_group_articles_flat = []
        for group in st.session_state.auto_groups:
            all_auto_group_articles_flat.extend(group['articles'])
        current_display_articles = all_auto_group_articles_flat
    # íŠ¹ì • ìë™ ê·¸ë£¹ ì„ íƒ ì˜µì…˜ì€ ì´ì œ ì—†ìœ¼ë¯€ë¡œ ì œê±°

    # ì „ì²´ ì„ íƒ/í•´ì œ ë²„íŠ¼ (current_display_articlesë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‘ë™)
    col_select_all, _ = st.columns([0.3, 0.7])
    with col_select_all:
        if st.button("âœ… ì „ì²´ ì„ íƒ"):
            st.session_state.selected_keys = [art['url'] for art in current_display_articles]
        if st.button("âŒ ì „ì²´ í•´ì œ"):
            st.session_state.selected_keys = []

    # ë³µì‚¬í•  ê¸°ì‚¬ë“¤ì„ ë‹´ì„ ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”
    final_copy_list_for_textarea = [] 

    # --- "ë³µì‚¬í•  ë‰´ìŠ¤ ëª©ë¡" ë‚´ìš© êµ¬ì„± ë¡œì§ ---
    if st.session_state.selected_display_mode == "all_individual":
        # 'ëª¨ë“  ê¸°ì‚¬ (ê°œë³„ ë³´ê¸°)' ì„ íƒ ì‹œ: 'ì„ íƒ'ëœ ëª¨ë“  ê¸°ì‚¬ë¥¼ 'â– ' í˜•ì‹ìœ¼ë¡œ í‘œì‹œ
        for art in st.session_state.final_articles: # ëª¨ë“  ê¸°ì‚¬ ëª©ë¡ì„ ê¸°ì¤€ìœ¼ë¡œ
            key = art['url']
            if key in st.session_state.selected_keys:
                final_copy_list_for_textarea.append(f"â–  {art['title']} ({art['press']})\n{convert_to_mobile_link(art['url'])}")
    
    elif st.session_state.selected_display_mode == "no_manual_group":
        # 'ê·¸ë£¹ ì—†ëŠ” ê¸°ì‚¬ ë³´ê¸°' ì„ íƒ ì‹œ: ìˆ˜ë™ ê·¸ë£¹í™”ë˜ì§€ ì•Šì€ ê¸°ì‚¬ ì¤‘ 'ì„ íƒ'ëœ ê¸°ì‚¬ë§Œ í‘œì‹œ
        final_copy_list_for_textarea.append("â–  ê·¸ë£¹ ì—†ëŠ” ê¸°ì‚¬ ê´€ë ¨")
        filtered_for_copy = []
        for art in st.session_state.final_articles: # ëª¨ë“  ê¸°ì‚¬ ëª©ë¡ì„ ê¸°ì¤€ìœ¼ë¡œ
            key = art['url']
            if key in st.session_state.selected_keys and key not in st.session_state.manual_grouped_keys:
                filtered_for_copy.append(f"â–  {art['title']} ({art['press']})\n{convert_to_mobile_link(art['url'])}")
        
        if filtered_for_copy:
            final_copy_list_for_textarea.extend(filtered_for_copy)
        else: # ì œëª©ë§Œ ìˆê³  ê¸°ì‚¬ê°€ ì—†ìœ¼ë©´
             final_copy_list_for_textarea = ["ì„ íƒëœ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤."]

    elif st.session_state.selected_display_mode == "all_auto_groups":
        # 'ê·¸ë£¹í™”ëœ ê¸°ì‚¬ë§Œ ë³´ê¸°' ì„ íƒ ì‹œ: ëª¨ë“  ìë™ ê·¸ë£¹ì„ í‘œì‹œí•˜ê³ , ê° ê·¸ë£¹ ë‚´ 'ì„ íƒ'ëœ ê¸°ì‚¬ë“¤ì„ í¬í•¨
        for group in st.session_state.auto_groups:
            selected_articles_in_this_auto_group = []
            for art in group['articles']:
                key = art['url']
                if key in st.session_state.selected_keys:
                    selected_articles_in_this_auto_group.append(f"- {art['title']} ({art['press']})\n{convert_to_mobile_link(art['url'])}")
            
            if selected_articles_in_this_auto_group:
                # ìë™ ê·¸ë£¹ ì œëª© ìƒì„±
                auto_group_title = "â–  ê·¸ë£¹ ê¸°ì‚¬ ê´€ë ¨"
                if group['common_keywords']:
                    common_kws = group['common_keywords']
                    if len(common_kws) > 2:
                        title_kws = ", ".join(common_kws[:2]) + "..."
                    else:
                        title_kws = ", ".join(common_kws)
                    auto_group_title = f"â–  {title_kws} ê´€ë ¨"
                
                final_copy_list_for_textarea.append(auto_group_title)
                final_copy_list_for_textarea.extend(selected_articles_in_this_auto_group)
        if not final_copy_list_for_textarea: # ëª¨ë“  ìë™ ê·¸ë£¹ì—ì„œ ì„ íƒëœ ê¸°ì‚¬ê°€ ì—†ìœ¼ë©´
            final_copy_list_for_textarea = ["ì„ íƒëœ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤."]
    
    # --- ê°œë³„ ê¸°ì‚¬ í‘œì‹œ (UIì— ë³´ì´ëŠ” ë¶€ë¶„) ---
    if st.session_state.selected_display_mode == "all_auto_groups":
        # 'ê·¸ë£¹í™”ëœ ê¸°ì‚¬ë§Œ ë³´ê¸°'ì¼ ë•Œë§Œ ë³´ì´ëŠ” ë§ˆìŠ¤í„° ì²´í¬ë°•ìŠ¤ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
        # ì´ ë§ˆìŠ¤í„° ì²´í¬ë°•ìŠ¤ëŠ” ëª¨ë“  ìë™ ê·¸ë£¹ì˜ ê¸°ì‚¬ë¥¼ ì„ íƒ/í•´ì œí•˜ëŠ” ì—­í• 
        def update_all_auto_groups_selection_master():
            all_auto_group_urls = []
            for group in st.session_state.auto_groups:
                all_auto_group_urls.extend([art['url'] for art in group['articles']])
            
            if st.session_state.select_all_auto_groups_master_checkbox:
                st.session_state.selected_keys = list(set(st.session_state.selected_keys + all_auto_group_urls))
            else:
                st.session_state.selected_keys = [url for url in st.session_state.selected_keys if url not in all_auto_group_urls]
            st.experimental_rerun() # ë³€ê²½ ì‚¬í•­ ì¦‰ì‹œ ë°˜ì˜

        all_auto_group_urls_set = set()
        for group in st.session_state.auto_groups:
            all_auto_group_urls_set.update([art['url'] for art in group['articles']])
        
        is_all_auto_groups_selected_master = all(url in st.session_state.selected_keys for url in all_auto_group_urls_set) and len(all_auto_group_urls_set) > 0

        st.checkbox(
            "âœ… ëª¨ë“  ìë™ ê·¸ë£¹ ê¸°ì‚¬ ì „ì²´ ì„ íƒ/í•´ì œ", # ë§ˆìŠ¤í„° ì²´í¬ë°•ìŠ¤ ëª…ì¹­ ë³€ê²½
            value=is_all_auto_groups_selected_master,
            key="select_all_auto_groups_master_checkbox",
            on_change=update_all_auto_groups_selection_master
        )
        st.markdown("---") # êµ¬ë¶„ì„  ì¶”ê°€

        for group_idx, group in enumerate(st.session_state.auto_groups):
            group_title_keywords = group['common_keywords']
            group_urls = [art['url'] for art in group['articles']]
            
            # íŠ¹ì • ê·¸ë£¹ì˜ ëª¨ë“  ê¸°ì‚¬ê°€ ì„ íƒë˜ì—ˆëŠ”ì§€ í™•ì¸
            is_this_group_selected = all(url in st.session_state.selected_keys for url in group_urls) and len(group_urls) > 0

            # ê·¸ë£¹ë³„ ì„ íƒ/í•´ì œ ì²´í¬ë°•ìŠ¤ ì½œë°± í•¨ìˆ˜
            def update_group_selection(current_group_urls, group_checkbox_key):
                if st.session_state[group_checkbox_key]:
                    st.session_state.selected_keys = list(set(st.session_state.selected_keys + current_group_urls))
                else:
                    st.session_state.selected_keys = [url for url in st.session_state.selected_keys if url not in current_group_urls]
                st.experimental_rerun() # ë³€ê²½ ì‚¬í•­ ì¦‰ì‹œ ë°˜ì˜

            # ê·¸ë£¹ ì œëª©ê³¼ ê·¸ë£¹ ì„ íƒ ì²´í¬ë°•ìŠ¤ë¥¼ í•œ ì¤„ì— í‘œì‹œ
            col_group_title, col_group_checkbox = st.columns([0.8, 0.2])
            with col_group_title:
                if group_title_keywords:
                    if len(group_title_keywords) > 2:
                        title_kws = ", ".join(group_title_keywords[:2]) + "..."
                    else:
                        title_kws = ", ".join(group_title_keywords)
                    st.markdown(f"**### ìë™ ê·¸ë£¹ {group_idx + 1}: {title_kws} ê´€ë ¨ ({len(group['articles'])}ê±´)**")
                else:
                    st.markdown(f"**### ìë™ ê·¸ë£¹ {group_idx + 1} ({len(group['articles'])}ê±´)**")
            with col_group_checkbox:
                st.checkbox(
                    "ê·¸ë£¹ ì„ íƒ",
                    value=is_this_group_selected,
                    key=f"group_select_checkbox_{group_idx}",
                    on_change=update_group_selection,
                    args=(group_urls, f"group_select_checkbox_{group_idx}")
                )
            
            for art in group['articles']: # ê·¸ë£¹ ë‚´ ê¸°ì‚¬ë“¤ì„ í‘œì‹œ
                key = art['url']
                
                def update_selection(item_key):
                    if st.session_state[f"checkbox_{item_key}"]:
                        if item_key not in st.session_state.selected_keys:
                            st.session_state.selected_keys.append(item_key)
                    else:
                        if item_key in st.session_state.selected_keys:
                            st.session_state.selected_keys.remove(item_key)
                    st.experimental_rerun() # ë³€ê²½ ì‚¬í•­ ì¦‰ì‹œ ë°˜ì˜

                def update_manual_grouping(item_key):
                    if st.session_state[f"manual_group_checkbox_{item_key}"]:
                        if item_key not in st.session_state.manual_grouped_keys:
                            st.session_state.manual_grouped_keys.append(item_key)
                    else:
                        if item_key in st.session_state.manual_grouped_keys:
                            st.session_state.manual_grouped_keys.remove(item_key)
                    st.experimental_rerun() # ë³€ê²½ ì‚¬í•­ ì¦‰ì‹œ ë°˜ì˜

                st.markdown(
                    f"<div style='user-select: text;'>â–  {art['title']} ({art['press']})</div>",
                    unsafe_allow_html=True
                )
                st.markdown(
                    f"<div style='color:gray;font-size:13px;'>ğŸ•’ {art['pubdate']} | í‚¤ì›Œë“œ: {', '.join(art['matched'])}</div>",
                    unsafe_allow_html=True
                )
                
                col_checkbox_select, col_checkbox_group = st.columns([0.2, 0.8])

                with col_checkbox_select:
                    st.checkbox(
                        "ì„ íƒ", 
                        value=(key in st.session_state.selected_keys), 
                        key=f"checkbox_{key}", 
                        on_change=update_selection, 
                        args=(key,)
                    )
                
                with col_checkbox_group:
                    st.checkbox(
                        "ê·¸ë£¹ ë§Œë“¤ê¸°", 
                        value=(key in st.session_state.manual_grouped_keys), 
                        key=f"manual_group_checkbox_{key}", 
                        on_change=update_manual_grouping, 
                        args=(key,),
                        disabled=False, 
                        help="ì´ ê¸°ì‚¬ë¥¼ ìˆ˜ë™ ê·¸ë£¹ì— í¬í•¨í•©ë‹ˆë‹¤." 
                    )

                col_preview, col_copy = st.columns([0.75, 0.25])
                with col_preview:
                    st.markdown(f"[ğŸ“ ê¸°ì‚¬ ë°”ë¡œë³´ê¸°]({convert_to_mobile_link(art['url'])})")
                with col_copy:
                    if st.button("ğŸ“‹ 1ê±´ ë³µì‚¬", key=f"copy_{key}"):
                        # 1ê±´ ë³µì‚¬ëŠ” ê·¸ëƒ¥ ì„ íƒëœ ê¸°ì‚¬ í˜•ì‹ìœ¼ë¡œ (â–  ì œëª© (ì–¸ë¡ ì‚¬))
                        ctext = f"â–  {art['title']} ({art['press']})\n{convert_to_mobile_link(art['url'])}"
                        st.session_state.copied_text = ctext
                        st.experimental_rerun()

                if st.session_state.get("copied_text", "").startswith(f"â–  {art['title']}"):
                    st.text_area("ë³µì‚¬ëœ ë‚´ìš©", st.session_state.copied_text, height=80, key=f"copied_area_{key}")
                st.markdown("---") # ê·¸ë£¹ ë‚´ ê¸°ì‚¬ êµ¬ë¶„ì„ 
        
        if not st.session_state.auto_groups:
            st.info("ìë™ìœ¼ë¡œ ê·¸ë£¹í™”ëœ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")

    else: # 'ëª¨ë“  ê¸°ì‚¬ (ê°œë³„ ë³´ê¸°)' ë˜ëŠ” 'ê·¸ë£¹ ì—†ëŠ” ê¸°ì‚¬ ë³´ê¸°' ì„ íƒ ì‹œ
        # 'ê·¸ë£¹ ì—†ëŠ” ê¸°ì‚¬ ë³´ê¸°'ì¼ ê²½ìš° í•„í„°ë§
        articles_to_display_in_loop = []
        if st.session_state.selected_display_mode == "no_manual_group":
            articles_to_display_in_loop = [
                art for art in current_display_articles if art['url'] not in st.session_state.manual_grouped_keys
            ]
            if not articles_to_display_in_loop:
                st.info("ê·¸ë£¹ ì—†ëŠ” ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else: # all_individual
            articles_to_display_in_loop = current_display_articles


        for art in articles_to_display_in_loop: # í˜„ì¬ í‘œì‹œë  ê¸°ì‚¬ ëª©ë¡ ì‚¬ìš©
            key = art['url']
            
            def update_selection(item_key):
                if st.session_state[f"checkbox_{item_key}"]:
                    if item_key not in st.session_state.selected_keys:
                        st.session_state.selected_keys.append(item_key)
                else:
                    if item_key in st.session_state.selected_keys:
                        st.session_state.selected_keys.remove(item_key)
                st.experimental_rerun() # ë³€ê²½ ì‚¬í•­ ì¦‰ì‹œ ë°˜ì˜

            def update_manual_grouping(item_key):
                if st.session_state[f"manual_group_checkbox_{item_key}"]:
                    if item_key not in st.session_state.manual_grouped_keys:
                        st.session_state.manual_grouped_keys.append(item_key)
                else:
                    if item_key in st.session_state.manual_grouped_keys:
                        st.session_state.manual_grouped_keys.remove(item_key)
                st.experimental_rerun() # ë³€ê²½ ì‚¬í•­ ì¦‰ì‹œ ë°˜ì˜

            # ê¸°ì‚¬ ì œëª©ê³¼ ì–¸ë¡ ì‚¬ í‘œì‹œ (UI í‘œì‹œìš©)
            st.markdown(
                f"<div style='user-select: text;'>â–  {art['title']} ({art['press']})</div>",
                unsafe_allow_html=True
            )
            # ë°œí–‰ì¼ê³¼ ë§¤ì¹­ëœ í‚¤ì›Œë“œ í‘œì‹œ
            st.markdown(
                f"<div style='color:gray;font-size:13px;'>ï¿½ {art['pubdate']} | í‚¤ì›Œë“œ: {', '.join(art['matched'])}</div>",
                unsafe_allow_html=True
            )
            
            col_checkbox_select, col_checkbox_group = st.columns([0.2, 0.8])

            with col_checkbox_select:
                st.checkbox(
                    "ì„ íƒ", 
                    value=(key in st.session_state.selected_keys), 
                    key=f"checkbox_{key}", 
                    on_change=update_selection, 
                    args=(key,)
                )
            
            with col_checkbox_group:
                # 'ê·¸ë£¹ ë§Œë“¤ê¸°' ì²´í¬ë°•ìŠ¤ë¥¼ í•­ìƒ í™œì„±í™”
                st.checkbox(
                    "ê·¸ë£¹ ë§Œë“¤ê¸°", 
                    value=(key in st.session_state.manual_grouped_keys), 
                    key=f"manual_group_checkbox_{key}", 
                    on_change=update_manual_grouping, 
                    args=(key,),
                    disabled=False, 
                    help="ì´ ê¸°ì‚¬ë¥¼ ìˆ˜ë™ ê·¸ë£¹ì— í¬í•¨í•©ë‹ˆë‹¤." 
                )

            # ê¸°ì‚¬ ë°”ë¡œë³´ê¸° ë§í¬ ë° 1ê±´ ë³µì‚¬ ë²„íŠ¼
            col_preview, col_copy = st.columns([0.75, 0.25])
            with col_preview:
                st.markdown(f"[ğŸ“ ê¸°ì‚¬ ë°”ë¡œë³´ê¸°]({convert_to_mobile_link(art['url'])})")
            with col_copy:
                if st.button("ğŸ“‹ 1ê±´ ë³µì‚¬", key=f"copy_{key}"):
                    # 1ê±´ ë³µì‚¬ëŠ” ê·¸ëƒ¥ ì„ íƒëœ ê¸°ì‚¬ í˜•ì‹ìœ¼ë¡œ (â–  ì œëª© (ì–¸ë¡ ì‚¬))
                    ctext = f"â–  {art['title']} ({art['press']})\n{convert_to_mobile_link(art['url'])}"
                    st.session_state.copied_text = ctext
                    st.experimental_rerun()

            # ë³µì‚¬ëœ ë‚´ìš© í‘œì‹œ (ê°€ì¥ ìµœê·¼ ë³µì‚¬ëœ 1ê±´ë§Œ)
            if st.session_state.get("copied_text", "").startswith(f"â–  {art['title']}"):
                st.text_area("ë³µì‚¬ëœ ë‚´ìš©", st.session_state.copied_text, height=80, key=f"copied_area_{key}")

    final_txt = "\n\n".join(final_copy_list_for_textarea)

    st.text_area("ğŸ“ ë³µì‚¬í•  ë‰´ìŠ¤ ëª©ë¡", final_txt, height=300)
    
    # ë³µì‚¬ ë‚´ìš© ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
    st.download_button("ğŸ“„ ë³µì‚¬ ë‚´ìš© ë‹¤ìš´ë¡œë“œ (.txt)", final_txt, file_name="news.txt")
    st.markdown("ğŸ“‹ ìœ„ í…ìŠ¤íŠ¸ë¥¼ ì§ì ‘ ë³µì‚¬í•˜ê±°ë‚˜ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ì„ ëˆŒëŸ¬ ì €ì¥í•˜ì„¸ìš”.")
ï¿½
