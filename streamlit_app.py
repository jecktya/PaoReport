import streamlit as st
import requests
from bs4 import BeautifulSoup
from datetime import datetime
import re

NAVER_SEARCH_URL = "https://search.naver.com/search.naver"

def get_recent_articles(keywords):
    headers = {"User-Agent": "Mozilla/5.0"}
    articles = []

    for keyword in keywords:
        params = {
            "where": "news",
            "query": keyword,
            "sort": 1,  # ìµœì‹ ìˆœ
        }

        response = requests.get(NAVER_SEARCH_URL, params=params, headers=headers)
        soup = BeautifulSoup(response.text, "html.parser")
        news_items = soup.select("ul.list_news > li")

        for item in news_items:
            try:
                title_tag = item.select_one("a.news_tit")
                if not title_tag:
                    continue

                title = title_tag["title"]
                url = title_tag["href"]
                press_tag = item.select_one("a.info.press")
                press_name = press_tag.text.strip() if press_tag else "Unknown"

                time_tag = item.select("span.info")[-1].text  # ë§ˆì§€ë§‰ infoê°€ ì‹œê°„ ì •ë³´ì¸ ê²½ìš°ê°€ ë§ìŒ
                match = re.search(r"(\d+)(ë¶„|ì‹œê°„) ì „", time_tag)
                if not match:
                    continue

                value, unit = int(match.group(1)), match.group(2)
                if (unit == "ì‹œê°„" and value <= 4) or (unit == "ë¶„"):
                    articles.append({
                        "title": title,
                        "url": url,
                        "press": press_name,
                        "key": f"{title}_{url}"
                    })
            except:
                continue

    # ì¤‘ë³µ ì œê±° (URL ê¸°ì¤€)
    unique_articles = {article['url']: article for article in articles}
    return list(unique_articles.values())

# ----- Streamlit App -----
st.title("ğŸ“° ìµœê·¼ 4ì‹œê°„ ì´ë‚´ êµ° ê´€ë ¨ ë‰´ìŠ¤")
st.markdown("ì˜ìƒ ë‰´ìŠ¤ êµ¬ë¶„ ì—†ì´, í‚¤ì›Œë“œ ê¸°ë°˜ ìµœì‹  ë‰´ìŠ¤ ê²€ìƒ‰ê¸°ì…ë‹ˆë‹¤.")

default_keywords = ["ìœ¡êµ°", "êµ­ë°©", "ì™¸êµ", "ì•ˆë³´", "ë¶í•œ",
                    "ì‹ ë³‘êµìœ¡ëŒ€", "í›ˆë ¨", "ê°„ë¶€", "ì¥êµ",
                    "ë¶€ì‚¬ê´€", "ë³‘ì‚¬", "ìš©ì‚¬", "êµ°ë¬´ì›"]

input_keywords = st.text_input("ê²€ìƒ‰ í‚¤ì›Œë“œ (ì‰¼í‘œë¡œ êµ¬ë¶„)", ", ".join(default_keywords))
keyword_list = [k.strip() for k in input_keywords.split(",") if k.strip()]

if st.button("ğŸ” ë‰´ìŠ¤ ê²€ìƒ‰"):
    with st.spinner("ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘ ì¤‘ì…ë‹ˆë‹¤..."):
        articles = get_recent_articles(keyword_list)

    if not articles:
        st.warning("ì¡°ê±´ì— ë§ëŠ” ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.subheader("ğŸ§¾ ê¸°ì‚¬ ë¯¸ë¦¬ë³´ê¸° (ì„ íƒí•´ì„œ ê²°ê³¼ ìƒì„±)")
        selected_keys = []

        for article in articles:
            key = article["key"]
            cols = st.columns([0.85, 0.15])
            with cols[0]:
                st.markdown(f"**{article['title']}** ({article['press']})")
            with cols[1]:
                checked = st.checkbox("âœ…", value=True, key=key)
                if checked:
                    selected_keys.append(key)

        if st.button("ğŸ“„ ì„ íƒëœ ê²°ê³¼ ì¶œë ¥"):
            st.subheader("ğŸ“Œ ì„ íƒëœ ë‰´ìŠ¤")
            for article in articles:
                if article["key"] in selected_keys:
                    st.markdown(f"â–  {article['title']} ({article['press']})")
                    st.markdown(f"{article['url']}\n")
